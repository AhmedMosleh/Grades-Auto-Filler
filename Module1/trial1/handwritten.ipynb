{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ff56687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# from scipy.misc.pilutil import imresize\n",
    "import cv2 #version 3.2.0\n",
    "from skimage.feature import hog\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from xlwt import Workbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e053a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#img_resized= np.array(Image.fromarray(obj=img, mode='F').resize(size=(width, height), resample=Image.BICUBIC)\n",
    "#Converting it in a excel-file\n",
    "#data.to_excel('c:Users.xlsx')\n",
    "#instead of library  \n",
    "# \n",
    "def _imshow(img):\n",
    "    cv2.imshow('image', img)\n",
    "    plt.show()\n",
    "    # specify a wait key from keyboard\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    if k == 27: #esc in keyboard\n",
    "        cv2.destroyAllWindows() #close the window   \n",
    "\n",
    "    elif k == ord('s'): #if order is s save the image\n",
    "        cv2.imwrite('Test.png', img) #write image in your pc     \n",
    "        cv2.destroyAllWindows() # close the window \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70081780",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGIT_WIDTH = 10\n",
    "DIGIT_HEIGHT = 20\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "CLASS_N = 10  # 0-9\n",
    "# This method splits the input training image into small cells (of a single digit) and uses these cells as training data.\n",
    "# The default training image (MNIST) is a 1000x1000 size image and each digit is of size 10x20. so we divide 1000/10 horizontally and 1000/20 vertically.\n",
    "def split2d(img, cell_size, flatten=True):\n",
    "    h, w = img.shape[:2]\n",
    "    sx, sy = cell_size\n",
    "    cells = [np.hsplit(row, w // sx) for row in np.vsplit(img, h // sy)]\n",
    "    cells = np.array(cells)\n",
    "    if flatten:\n",
    "        cells = cells.reshape(-1, sy, sx)\n",
    "    return cells\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "636bac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_digits(fn):\n",
    "    print('loading \"%s for training\" ...' % fn)\n",
    "    digits_img = cv2.imread(fn, 0)\n",
    "    digits = split2d(digits_img, (DIGIT_WIDTH, DIGIT_HEIGHT))\n",
    "    resized_digits = []\n",
    "    for digit in digits:\n",
    "        resized_digits.append(cv2.imresize(digit, (IMG_WIDTH, IMG_HEIGHT)))\n",
    "    labels = np.repeat(np.arange(CLASS_N), len(digits) / CLASS_N)\n",
    "    return np.array(resized_digits), labels            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80193fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_to_hog_20(img_array):\n",
    "    hog_featuresData = []\n",
    "    for img in img_array:\n",
    "        fd = hog(img,\n",
    "                 orientations=10,\n",
    "                 pixels_per_cell=(5, 5),\n",
    "                 cells_per_block=(1, 1),\n",
    "                 visualise=False)\n",
    "        hog_featuresData.append(fd)\n",
    "    hog_features = np.array(hog_featuresData, 'float64')\n",
    "    return np.float32(hog_features)\n",
    "                       \n",
    "                        \n",
    "def get_digits(contours, hierarchy):\n",
    "    hierarchy = hierarchy[0]\n",
    "    bounding_rectangles = [cv2.boundingRect(ctr) for ctr in contours]\n",
    "    final_bounding_rectangles = []\n",
    "    # find the most common heirarchy level - that is where our digits's bounding boxes are\n",
    "    u, indices = np.unique(hierarchy[:, -1], return_inverse=True)\n",
    "    most_common_heirarchy = u[np.argmax(np.bincount(indices))]\n",
    "\n",
    "    for r, hr in zip(bounding_rectangles, hierarchy):\n",
    "        x, y, w, h = r\n",
    "        # this could vary depending on the image you are trying to predict\n",
    "        # we are trying to extract ONLY the rectangles with images in it (this is a very simple way to do it)\n",
    "        # we use heirarchy to extract only the boxes that are in the same global level - to avoid digits inside other digits\n",
    "        # ex: there could be a bounding box inside every 6,9,8 because of the loops in the number's appearence - we don't want that.\n",
    "        # read more about it here: https://docs.opencv.org/trunk/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "        if ((w * h) > 250) and (10 <= w <= 200) and (10 <= h <= 200) and hr[3] == most_common_heirarchy:\n",
    "            final_bounding_rectangles.append(r)\n",
    "\n",
    "    return final_bounding_rectangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "340a7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_user_img(img_file, model):\n",
    "    print('loading \"%s for digit recognition\" ...' % img_file)\n",
    "    im = cv2.imread(img_file)\n",
    "    blank_image = np.zeros((im.shape[0], im.shape[1], 3), np.uint8)\n",
    "    blank_image.fill(255)\n",
    "    numbers = []\n",
    "\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    # plt.imshow(imgray)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "    thresh = cv2.erode(thresh, kernel, iterations=1)\n",
    "    thresh = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    thresh = cv2.erode(thresh, kernel, iterations=1)\n",
    "\n",
    "    _, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    digits_rectangles = get_digits(contours, hierarchy)  # rectangles of bounding the digits in user image\n",
    "\n",
    "    for rect in digits_rectangles:\n",
    "        x, y, w, h = rect\n",
    "        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        im_digit = imgray[y:y + h, x:x + w]\n",
    "        im_digit = (255 - im_digit)\n",
    "        im_digit = cv2.imresize(im_digit, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "        hog_img_data = pixels_to_hog_20([im_digit])\n",
    "        pred = model.predict(hog_img_data)\n",
    "        cv2.putText(im, str(int(pred[0])), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 3)\n",
    "        numbers.append(str(int(pred[0])))\n",
    "        cv2.putText(blank_image, str(int(pred[0])), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 5)\n",
    "\n",
    "    # plt.imshow(im)\n",
    "    cv2.imwrite(\"original_overlay.png\", im)\n",
    "    cv2.imwrite(\"final_digits.png\", blank_image)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76f28a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_precedence(contour, cols):\n",
    "    return contour[1] * cols + contour[0]  # row-wise ordering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "426985b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function processes a custom training image\n",
    "def load_digits_custom(img_file, ):\n",
    "    train_data = []\n",
    "    # pd.read_csv('train.csv')\n",
    "    # train_data=\n",
    "    train_target = []\n",
    "    start_class = 1\n",
    "    im = cv2.imread(img_file)\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    # plt.imshow(imgray)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "    thresh = cv2.erode(thresh, kernel, iterations=1)\n",
    "    thresh = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    thresh = cv2.erode(thresh, kernel, iterations=1)\n",
    "\n",
    "    _, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    digits_rectangles = get_digits(contours, hierarchy)  # rectangles of bounding the digits in user image\n",
    "\n",
    "    # sort rectangles accoring to x,y pos so that we can label them\n",
    "    digits_rectangles.sort(key=lambda x: get_contour_precedence(x, im.shape[1]))\n",
    "\n",
    "    for index, rect in enumerate(digits_rectangles):\n",
    "        x, y, w, h = rect\n",
    "        cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        im_digit = imgray[y:y + h, x:x + w]\n",
    "        im_digit = (255 - im_digit)\n",
    "\n",
    "        im_digit = cv2.imresize(im_digit, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        train_data.append(im_digit)\n",
    "        train_target.append(start_class % 10)\n",
    "\n",
    "        if index > 0 and (index + 1) % 10 == 0:\n",
    "            start_class += 1\n",
    "    cv2.imwrite(\"training_box_overlay.png\", im)\n",
    "\n",
    "    return np.array(train_data), np.array(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4e5fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Num_Classifier(img_test):\n",
    "    TRAIN_MNIST_IMG = 'digits.png'\n",
    "    TRAIN_USER_IMG = 'custom_train_digits.jpg'\n",
    "    TEST_USER_IMG = img_test\n",
    "    # digits, labels = load_digits(TRAIN_MNIST_IMG) #original MNIST data (not good detection)\n",
    "    digits, labels = load_digits_custom(\n",
    "        TRAIN_USER_IMG)  # my handwritten dataset (better than MNIST on my handwritten digits)\n",
    "\n",
    "    print('train data shape', digits.shape)\n",
    "    print('test data shape', labels.shape)\n",
    "\n",
    "    digits, labels = shuffle(digits, labels, random_state=256)\n",
    "    train_digits_data = pixels_to_hog_20(digits)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_digits_data, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    # ------------------training and testing----------------------------------------\n",
    "\n",
    "    model = KNN_MODEL(k=7)\n",
    "    model.train(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, preds))\n",
    "\n",
    "    model = KNN_MODEL(k=7)\n",
    "    model.train(train_digits_data, labels)\n",
    "    numbers = proc_user_img(TEST_USER_IMG, model)\n",
    "\n",
    "    model = SVM_MODEL(num_feats=train_digits_data.shape[1])\n",
    "    model.train(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print('Accuracy: ', accuracy_score(y_test, preds))\n",
    "\n",
    "    model = SVM_MODEL(num_feats=train_digits_data.shape[1])\n",
    "    model.train(train_digits_data, labels)\n",
    "    proc_user_img(TEST_USER_IMG, model)\n",
    "    w = \"\"\n",
    "    for i in reversed(numbers):\n",
    "        w += i + \"\"\n",
    "\n",
    "    return w\n",
    "##################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c18b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NumDetect_OCR(img):\n",
    "    output=cv.imread(img)\n",
    "    #RGB 2 GRAY\n",
    "    output = cv.cvtColor(output, cv.COLOR_BGR2GRAY)\n",
    "    #cv.imshow(\"imageResized GS\",output)\n",
    "    result=np.copy(output)\n",
    "    ret, thresh = cv.threshold(result, 100, 255, 0)\n",
    "    # cv.imshow(\"threshold result\",thresh)\n",
    "    #resize image\n",
    "    scale_percentw = 250\n",
    "    scale_percenth=300\n",
    "    width = int(thresh.shape[1] * scale_percentw / 100)\n",
    "    height = int(thresh.shape[0] * scale_percenth / 100)\n",
    "    dsize = (width, height)\n",
    "    output = cv.resize(thresh, dsize)\n",
    "    #output=thresh2\n",
    "    #cv.imwrite(\"white92.png\",output\n",
    "    SE = np.ones((3, 3), np.uint8)\n",
    "    output=cv.erode(output,SE)\n",
    "    cv.imwrite(\".png\",output)\n",
    "    #OCR\n",
    "    text = pytesseract.image_to_string(output, lang=\"eng\")  #Specify language to look after!\n",
    "    cv.imwrite(\"secnum%s.png\" % text, output)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecfb03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NameDetect_OCR(img):\n",
    "    output=cv.imread(img)\n",
    "    #RGB 2 GRAY\n",
    "    output = cv.cvtColor(output, cv.COLOR_BGR2GRAY)\n",
    "    #cv.imshow(\"imageResized GS\",output)\n",
    "    #invertthresh\n",
    "    ret, thresh = cv.threshold(output,150, 255, 0)\n",
    "    #cv.imshow(\"threshold\",thresh)\n",
    "    result=np.copy(output)\n",
    "    # Remove horizontal lines\n",
    "    horizontal_kernel = cv.getStructuringElement(cv.MORPH_RECT, (40,1))\n",
    "    remove_horizontal = cv.morphologyEx(thresh, cv.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    cnts = cv.findContours(remove_horizontal, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        cv.drawContours(result, [c], -1, (255,255,255), 2)\n",
    "    # cv.imshow('H',result)\n",
    "    ret, thresh2 = cv.threshold(result, 150, 255, 0)\n",
    "    #cv.imshow(\"threshold result\",thresh2)\n",
    "    #resize image\n",
    "    scale_percentw = 250\n",
    "    scale_percenth=300\n",
    "    width = int(thresh2.shape[1] * scale_percentw / 100)\n",
    "    height = int(thresh2.shape[0] * scale_percenth / 100)\n",
    "    dsize = (width, height)\n",
    "    output = cv.resize(thresh2, dsize)\n",
    "    #cv.imshow(\"big\",output)\n",
    "    #OCR\n",
    "    text = pytesseract.image_to_string(output, lang=\"ara\")  #Specify language to look after!\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86b5a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadImages(directory):\n",
    "    fnames = os.listdir(directory)\n",
    "    to_return = []\n",
    "    for fn in fnames:\n",
    "        path = os.path.join(directory, fn)\n",
    "        gray_scale_image = cv.cvtColor(cv.imread(path), cv.COLOR_BGR2GRAY)\n",
    "        to_return.append((fn, gray_scale_image))\n",
    "\n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b24a93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeImage(image, width = None, height = None, inter = cv.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e8c6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveDuplicates(lines):\n",
    "    for i, (rho, theta) in enumerate(lines):\n",
    "        for j, (rho2, theta2) in enumerate(lines):\n",
    "            if j == i:\n",
    "                continue\n",
    "            deltaRho = abs(abs(rho) - abs(rho2))\n",
    "            deltaTheta = abs(abs(theta) - abs(theta2))\n",
    "            if deltaRho < 15 and deltaTheta < 25.0/180.0:\n",
    "                del lines[j]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b283814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SortLinesList(lines):\n",
    "    vertical = []\n",
    "    horizontal = []\n",
    "    for rho, theta in lines:\n",
    "        if theta > 1 and theta < 2:\n",
    "            horizontal.append((rho, theta))\n",
    "        else:\n",
    "            vertical.append((rho, theta))\n",
    "    return horizontal, vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fac7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixList(list):\n",
    "    newList = []\n",
    "    for item in list:\n",
    "        newList.append(item[0])\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ee72fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Closing(img):\n",
    "    SE = np.ones((5, 5), np.uint8)\n",
    "    SE2 = np.ones((3, 3), np.uint8)\n",
    "    ret, img = cv.threshold(img, 70, 255, cv.THRESH_BINARY)\n",
    "    img = cv.dilate(img, SE)\n",
    "    img = cv.erode(img, SE)\n",
    "    img = cv.dilate(img, SE)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bd2a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddLines(lines, img):\n",
    "    if lines is not None:\n",
    "        for rho, theta in lines:\n",
    "            a = math.cos(theta)\n",
    "            b = math.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            #print(\"line at (x,y) = (\", x0, \", \", y0, \") has rho, theta = \", rho, theta)\n",
    "            pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))\n",
    "            pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))\n",
    "            cv.line(img, pt1, pt2, (0, 0, 255), 3, cv.LINE_AA)\n",
    "\n",
    "    return lines, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ed88f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckCorrectOrDash(orig_img):\n",
    "    h, w = orig_img.shape\n",
    "    #threshold the image\n",
    "    ret, img = cv.threshold(orig_img, 150, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    #divide it into two parts\n",
    "    left, right = img[:, 0:int(w / 2)], img[:, int(w / 2):w]\n",
    "    \n",
    "    #get canny edges in both halves\n",
    "    canny_left_img = cv.Canny(left, threshold1=50, threshold2=200)\n",
    "    if (canny_left_img is None):\n",
    "        return ''\n",
    "\n",
    "    canny_right_img = cv.Canny(right, threshold1=50, threshold2=200)\n",
    "    if (canny_right_img is None):\n",
    "        return ''\n",
    "\n",
    "    #get Hough lines in both parts\n",
    "    lines_left_temp = cv.HoughLinesP(canny_left_img, 1, np.pi / 25.0, 5)\n",
    "    if (lines_left_temp is None):\n",
    "        return ''\n",
    "    lines_left = FixList(lines_left_temp)\n",
    "    \n",
    "    lines_right_temp = cv.HoughLinesP(canny_right_img, 1, np.pi / 25.0, 5)\n",
    "    if (lines_right_temp is None):\n",
    "        return ''\n",
    "    lines_right = FixList(lines_right_temp)\n",
    "\n",
    "    # get max line in length in left image and right image\n",
    "    max_left_line = []\n",
    "    max_right_line = []\n",
    "    max_len_left = 0\n",
    "    max_len_right = 0\n",
    "\n",
    "    for x1, y1, x2, y2 in lines_left:\n",
    "        length = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "        if length > max_len_left:\n",
    "            max_len_left = length\n",
    "            max_left_line = [x1, y1, x2, y2]\n",
    "        \n",
    "    for x1, y1, x2, y2 in lines_right:\n",
    "        length = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "        if length > max_len_right:\n",
    "            max_len_right = length\n",
    "            max_right_line = [x1, y1, x2, y2]\n",
    "        \n",
    "    # check angle between two lines\n",
    "    x1, y1, x2, y2 = max_left_line[0], max_left_line[1], max_left_line[2], max_left_line[3]\n",
    "    ang1 = math.atan(float(y2 - y1) / (x2 - x1))\n",
    "    \n",
    "    x1, y1, x2, y2 = max_right_line[0], max_right_line[1], max_right_line[2], max_right_line[3]\n",
    "    ang2 = math.atan(float(y2 - y1) / (x2 - x1))\n",
    "    \n",
    "    if abs(ang1) < 0.2 and abs(ang2) < 0.2:\n",
    "        # cell is dash\n",
    "        return 'dash'\n",
    "    else:\n",
    "        # cell is correct\n",
    "        return 'correct'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc582f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCells(pic):\n",
    "    img = pic.copy()\n",
    "    imgCopy = pic.copy()\n",
    "\n",
    "    # get canny edge image\n",
    "    canny_img = cv.Canny(img, 50, 350)\n",
    "\n",
    "    # get hough lines\n",
    "    linesTemp = cv.HoughLines(canny_img, 1, np.pi / 180.0, 270)\n",
    "\n",
    "    # just changing data structure\n",
    "    lines = FixList(linesTemp)\n",
    "\n",
    "    # removing duplicate hough lines\n",
    "    RemoveDuplicates(lines)\n",
    "\n",
    "    # separating lines into vertical and horizontal\n",
    "    hLines, vLines = SortLinesList(lines)\n",
    "\n",
    "    # add hough lines to the original image\n",
    "    lines, img = AddLines(lines, img)\n",
    "\n",
    "    #close the image to get an image with hough lines only and white background\n",
    "    closed_binary_image = Closing(img)\n",
    "\n",
    "    # find contours in the image\n",
    "    _, contours, hierachy = cv.findContours(closed_binary_image, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Trying to get y coordinates of the last row\n",
    "    contours = np.delete(contours, np.s_[0:5])\n",
    "    avg_height = 27\n",
    "    contours_info = []\n",
    "    w_min = 30\n",
    "    w_max = 200\n",
    "\n",
    "    # store x, y, w, h of right contours\n",
    "    for cont in contours:\n",
    "        x, y, w, h = cv.boundingRect(cont)\n",
    "\n",
    "        if (w < w_min or w > w_max + 20):\n",
    "            continue\n",
    "\n",
    "        if (h > avg_height+7 or h < avg_height - 7):\n",
    "            continue\n",
    "\n",
    "        contours_info.append([y, x, w, h])\n",
    "\n",
    "    # sort according to y value of the contours, to have the last row first, up to first row\n",
    "    np.sort(contours_info)\n",
    "\n",
    "    # just for testing purpose\n",
    "    # imgCopy = cv.drawContours(imgCopy, contours, -1, (255, 255, 255), 2)\n",
    "    # cv.imshow(\"contour image\", ResizeImage(imgCopy, height=775))\n",
    "\n",
    "    # can be changed according to the number of students in the sheet\n",
    "    folder_num = 34\n",
    "    last_width = 0\n",
    "    cnt = 0\n",
    "\n",
    "    # loop on contours, cut image, export it into seperate folders\n",
    "    for contour in contours_info:\n",
    "        y, x, w, h = contour\n",
    "        cv.rectangle(imgCopy, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    "\n",
    "        # Crop the result\n",
    "        final_image = imgCopy[y:y + h + 1, x:x + w + 1]\n",
    "\n",
    "        # check if I filled all student folders already, then the rest are false contours\n",
    "        if (folder_num <= 0):\n",
    "            break\n",
    "\n",
    "        # make directory imgs/student*folder_num*\n",
    "        dir = 'imgs/student%s' % folder_num\n",
    "\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "\n",
    "        # file name\n",
    "        fn = '%s/cell%s.png' % (dir, cnt)\n",
    "        # count of cells\n",
    "        cnt += 1\n",
    "        cv.imwrite(fn, final_image)\n",
    "        if last_width > 150:\n",
    "            folder_num -= 1\n",
    "            cnt = 0\n",
    "        last_width = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf2a7fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3188\\2476970242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReadImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'E:\\CUFE\\Fall22\\IP\\Project-2022\\GradesAutoFiller-main\\GradesAutoFiller-main\\Module1\\trial1\\dataset_module1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m_imshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mExtractCells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfolder_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m34\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Workbook is created\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3188\\4259769290.py\u001b[0m in \u001b[0;36mExtractCells\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# find contours in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierachy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosed_binary_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_LIST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Trying to get y coordinates of the last row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# __main__\n",
    "dataset = ReadImages(r'E:\\CUFE\\Fall22\\IP\\Project-2022\\GradesAutoFiller-main\\GradesAutoFiller-main\\Module1\\trial1\\dataset_module1')\n",
    "_imshow(dataset[1][1])\n",
    "ExtractCells(dataset[1][1])\n",
    "folder_num = 34\n",
    "# Workbook is created\n",
    "wb = Workbook()\n",
    "# add_sheet is used to create sheet.\n",
    "excel = wb.add_sheet('el dragat', cell_overwrite_ok=True)\n",
    "print('folders numbers', folder_num)\n",
    "for i in range(0,folder_num):\n",
    "    file_nm = \"imgs/student%s\" % (i+1)\n",
    "    file_length=len([f for f in os.listdir(file_nm)])\n",
    "    print('file length :', file_length)\n",
    "    for j in range(0, file_length):\n",
    "        file_name= file_nm + \"/cell%s.png\" % (j)\n",
    "        print(file_name)\n",
    "        image = cv.imread(file_name)\n",
    "        if (image is None):\n",
    "            break\n",
    "        shape=np.shape(image)\n",
    "        height=shape[0]\n",
    "        width=shape[1]\n",
    "\n",
    "        # height,width=image.shape\n",
    "\n",
    "        if (width > 150): # NAME\n",
    "            Name_text = NameDetect_OCR(file_name)\n",
    "            excel.write(i, 2, Name_text)\n",
    "\n",
    "        elif(width < 70 and width > 55 ): # NUMBER COMPUTER\n",
    "            Num_text=NumDetect_OCR(file_name)\n",
    "            excel.write(i, 0, Num_text)\n",
    "\n",
    "        else:  # NUMBER/correct/dash HANDWRITTEN WRITTEN\n",
    "\n",
    "            Num_written=Num_Classifier(file_name)\n",
    "            if(Num_written == \"\"):\n",
    "                string = CheckCorrectOrDash(image)\n",
    "                if (string == 'dash'):\n",
    "                    Num_written = '0'\n",
    "                elif (string == 'correct'):\n",
    "                    Num_written = '5'\n",
    "                else:\n",
    "                    break\n",
    "            excel.write(i, max(j, 3), Num_written)\n",
    "\n",
    "\n",
    "wb.save('el drgaaat.xls')\n",
    "\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db6522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014473db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "88033ea6e6aaf353f3d26ef69434bb9b1f089d6b00d896155ae24c39a5d92896"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
